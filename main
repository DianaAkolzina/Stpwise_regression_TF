import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Generate random data for regression
X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)

# Convert to DataFrame for better visualization
X_df = pd.DataFrame(X, columns=[f'Feature_{i}' for i in range(X.shape[1])])

# Split the data into 80% training and 20% testing sets
X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)

def stepwise_selection(X, y, initial_list=[], threshold_in=0.1, threshold_out=0.5, verbose=True):
    included = list(initial_list)
    while True:
        changed = False
        excluded = list(set(X.columns) - set(included))
        new_pval = pd.Series(index=excluded)
        for new_column in excluded:
            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()
            new_pval[new_column] = model.pvalues[new_column]
        best_pval = new_pval.min()
        if best_pval < threshold_in:
            best_feature = new_pval.idxmin()
            included.append(best_feature)
            changed = True
            if verbose:
                print(f'Added {best_feature} with p-value {best_pval}')

        # backward step
        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()
        # use all coefs except intercept
        pvalues = model.pvalues.iloc[1:]
        worst_pval = pvalues.max()
        if worst_pval > threshold_out:
            changed = True
            worst_feature = pvalues.idxmax()
            included.remove(worst_feature)
            if verbose:
                print(f'Dropped {worst_feature} with p-value {worst_pval}')
        if not changed:
            break
    return included

selected_features = stepwise_selection(X_train, y_train, verbose=True)
print(f'Selected features: {", ".join(selected_features)}')

# Train the final model with the selected features
X_train_selected = X_train[selected_features]
X_test_selected = X_test[selected_features]

model = sm.OLS(y_train, sm.add_constant(X_train_selected)).fit()
y_pred = model.predict(sm.add_constant(X_test_selected))

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean squared error: {mse}")
print(f"R-squared: {r2}")

# Visualize the selected features' correlation matrix
plt.figure(figsize=(10, 10))
sns.heatmap(X_train_selected.corr(), annot=True, cmap='coolwarm', square=True)
plt.title('Correlation Matrix of Selected Features')
plt.show()
